{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jtCMrvDhTd1F",
        "NnE1KN6NTc94"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Training"
      ],
      "metadata": {
        "id": "ZZBy6hxrRbNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "m5WYoaX3Ronb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "CZOEfzfh-3Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q Levenshtein\n",
        "! python -q -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_WLZvKL-4Dz",
        "outputId": "962a1aa1-2d00-4164-df06-779488fa914c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-15 15:10:09.637950: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-07-15 15:10:09.695559: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-15 15:10:10.756104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-trf==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.5.0/en_core_web_trf-3.5.0-py3-none-any.whl (460.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.3/460.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-trf==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-transformers<1.3.0,>=1.2.0.dev0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-trf==3.5.0) (1.2.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.10.11)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: transformers<4.31.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (4.30.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (0.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (0.3.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (8.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-trf==3.5.0) (2.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (2023.6.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy-transformers<1.3.0,>=1.2.0.dev0->en-core-web-trf==3.5.0) (1.3.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio\n",
        "import gdown\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy import spatial\n",
        "import en_core_web_sm\n",
        "import Levenshtein\n",
        "import nltk\n",
        "import dlib\n",
        "from datetime import datetime\n",
        "\n",
        "from skimage import exposure\n",
        "\n"
      ],
      "metadata": {
        "id": "3zrmc7hG-eg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the Data"
      ],
      "metadata": {
        "id": "f13BhtCxRi10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown 16ievG8aYUBMbn-6_docyrPD_4bLrJqtJ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnCsEVB5Mjoq",
        "outputId": "f8dd4acf-acbc-47ff-c1d4-58687361a54d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16ievG8aYUBMbn-6_docyrPD_4bLrJqtJ\n",
            "To: /content/processed_data_with_alignments.zip\n",
            "100% 639M/639M [00:06<00:00, 99.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip -q processed_data_with_alignments -d /content/data"
      ],
      "metadata": {
        "id": "tPRSI_07MsLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3132e2-93af-4813-b8a9-c7888699f643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/data/alignments/s17/lrbq1a.align? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Variables"
      ],
      "metadata": {
        "id": "pDAlqrVARzfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_speakers = np.arange(30, 35)"
      ],
      "metadata": {
        "id": "jCuMQgikARq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "invalid_speakers = [21,8,28]"
      ],
      "metadata": {
        "id": "upiPT_aiNHfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speakers = [speaker for speaker in range(1, 36) if speaker in selected_speakers and speaker not in invalid_speakers]"
      ],
      "metadata": {
        "id": "Wk1a-hEmNC8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(speakers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ciYNiH4NM3C",
        "outputId": "13589944-b388-4f14-f7ed-cd94e4f5822b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30, 31, 32, 33, 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cache_dir = '/content/data'\n",
        "alignment_dir = f'{cache_dir}/alignments'\n",
        "videos_dir = f'{cache_dir}/videos'"
      ],
      "metadata": {
        "id": "wAYMeOHyAZJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
      ],
      "metadata": {
        "id": "hU2ktXqBAZs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
        "\n",
        "num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1z10mO3Akqb",
        "outputId": "43023f40-8f09-4776-f0f1-f2a61af1f8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bad_videos = []"
      ],
      "metadata": {
        "id": "WXnpLANmPgd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Data and Alignments"
      ],
      "metadata": {
        "id": "dBHQVUiyR73t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video(path):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  frames = []\n",
        "\n",
        "  try:\n",
        "    for _ in range(frames_count):\n",
        "        ret, frame = cap.read()\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "        frames.append(frame)\n",
        "  except:\n",
        "    bad_videos.append(path)\n",
        "    print(\"error loading video\")\n",
        "    raise\n",
        "\n",
        "  cap.release()\n",
        "  mean = tf.math.reduce_mean(frames)\n",
        "  std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "\n",
        "  return tf.cast((frames - mean), tf.float32) / std"
      ],
      "metadata": {
        "id": "ze6SPrgWPVnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_alignment(path):\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens,' ',line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
      ],
      "metadata": {
        "id": "cUMhTsQcPl_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(video_path):\n",
        "    video_path = bytes.decode(video_path.numpy())\n",
        "    frames = load_video(video_path)\n",
        "    alignment_path = video_path.replace(\"videos\",\"alignments\").replace(\"mp4\",\"align\")\n",
        "    alignments = load_alignment(alignment_path)\n",
        "\n",
        "    return frames, alignments"
      ],
      "metadata": {
        "id": "rttmwG5RP1yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mappable_function(path):\n",
        "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
        "    return result"
      ],
      "metadata": {
        "id": "d36P-QyUPywO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Generic Functions"
      ],
      "metadata": {
        "id": "APMczji2V5cQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions For Metrics"
      ],
      "metadata": {
        "id": "Plg4M0-pWCXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`tensors_to_strings`** - A function which converts tensors to a string"
      ],
      "metadata": {
        "id": "yCbajK_WWJZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensors_to_strings(tensor_list):\n",
        "    string_list = []\n",
        "    for tensor in tensor_list:\n",
        "        # Convert tensor to string using K.eval()\n",
        "        string_value = tf.keras.backend.eval(tensor).decode('utf-8')  # Assuming UTF-8 encoding\n",
        "        string_list.append(string_value)\n",
        "\n",
        "    return string_list"
      ],
      "metadata": {
        "id": "JSzLmAXcWHMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`nlp_accuracy`** - A function which calculates the accuracy using nlp"
      ],
      "metadata": {
        "id": "kYI0UlacWsl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nlp_accuracy(y_true_string, y_pred_string):\n",
        "  nlp = en_core_web_sm.load()\n",
        "  result = 0\n",
        "\n",
        "  for true, pred in zip(y_true_string, y_pred_string):\n",
        "    true_doc, pred_doc = nlp(true).vector, nlp(pred).vector\n",
        "    result += (1 - spatial.distance.cosine(true_doc, pred_doc))\n",
        "\n",
        "  avg_accuracy = result / len(y_true_string)\n",
        "  return avg_accuracy"
      ],
      "metadata": {
        "id": "ifTFAvAbWsR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`levenstein_accuracy`** - A function which calculates and prints the accuracy using Levenstein"
      ],
      "metadata": {
        "id": "Taxc24-rXnS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def levenstein_accuracy(y_true_string, y_pred_string):\n",
        "  similarity = 0\n",
        "\n",
        "  for true, pred in zip(y_true_string, y_pred_string):\n",
        "    distance = Levenshtein.distance(true, pred)\n",
        "    max_length = max(len(true), len(pred))\n",
        "    similarity += (1 - (distance / max_length))\n",
        "    threshold = 0.8\n",
        "\n",
        "  avg_accuracy = similarity / len(y_true_string)\n",
        "  return avg_accuracy"
      ],
      "metadata": {
        "id": "pzuPzQfLXnlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Wer and Cer accuracy*\n",
        "\n",
        "**`calculate_wer`** - A function which calculates the wer accuracy for a single sentence\n",
        "\n",
        "**`calculate_cer`** - A function which calculates the cer accuracy for a single sentence\n",
        "\n",
        "**`wer_and_cer_accuracy`** - A function which calculates the average wer Cer accuracy"
      ],
      "metadata": {
        "id": "MjBbp5_LYPhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_tokens = reference.lower().split()\n",
        "    hypothesis_tokens = hypothesis.lower().split()\n",
        "\n",
        "    distance = nltk.edit_distance(reference_tokens, hypothesis_tokens)\n",
        "    wer = distance / len(reference_tokens)\n",
        "    return wer\n",
        "\n",
        "def calculate_cer(reference, hypothesis):\n",
        "    reference_chars = list(reference.lower())\n",
        "    hypothesis_chars = list(hypothesis.lower())\n",
        "\n",
        "    distance = nltk.edit_distance(reference_chars, hypothesis_chars)\n",
        "    cer = distance / len(reference_chars)\n",
        "    return cer\n",
        "\n",
        "def wer_and_cer_accuracy(y_true_string, y_pred_string):\n",
        "  wer_score, cer_score = 0, 0\n",
        "  for true, pred in zip(y_true_string, y_pred_string):\n",
        "    wer_score += calculate_wer(true, pred)\n",
        "    cer_score += calculate_cer(true, pred)\n",
        "\n",
        "  avg_wer = wer_score / len(y_true_string)\n",
        "  avg_cer = cer_score / len(y_true_string)\n",
        "\n",
        "  return avg_wer, avg_cer"
      ],
      "metadata": {
        "id": "YNOY_mXAYQAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Train and Test Datasets"
      ],
      "metadata": {
        "id": "NGs5mGlgA5K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation functions"
      ],
      "metadata": {
        "id": "lOcQJaUzRUUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_brightness_augmentation(frames):\n",
        "    brightness_factor = np.random.uniform(0.7, 1.3)\n",
        "    return frames * brightness_factor"
      ],
      "metadata": {
        "trusted": true,
        "id": "J3BTvoPD6yBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_flipping_augmentation(frames):\n",
        "   return tf.image.flip_left_right(frames)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y42LKtf86yBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data creation\n"
      ],
      "metadata": {
        "id": "ev5en-R0RcUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "train_percentage = 0.5\n",
        "\n",
        "data = tf.data.Dataset.list_files('./data/videos/*/*.mp4')\n",
        "data_count = len(data)\n",
        "print(data_count)\n",
        "preprocessed_data = data.shuffle(data_count, reshuffle_each_iteration=False).map(mappable_function).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_count = int(train_percentage * data_count)\n",
        "print(train_count)\n",
        "# Added for split\n",
        "# Batch size is 2 hard coded, bigger batch sizes caused problems\n",
        "train = preprocessed_data.take(train_count).padded_batch(1, padded_shapes=([75,None,None,None],[40])).take(2)\n",
        "test = preprocessed_data.skip(train_count).padded_batch(1, padded_shapes=([75,None,None,None],[40])).take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itNwQZ4-BAAD",
        "outputId": "15f9859c-72d3-4628-a2c8-dea953d297b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30852\n",
            "15426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train', len(train), 'test', len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIyU-mmja1Ds",
        "outputId": "b68ee56c-ec16-4015-8340-329d73fb68d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2 test 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take an example\n",
        "batch = train.as_numpy_iterator().next()\n",
        "batch_videos, batch_alignments = batch\n",
        "sample_video = batch_videos[0]\n",
        "sample_alignments = batch_alignments[0]\n",
        "\n",
        "# Save the example video as gif\n",
        "imageio.mimsave('./animation.gif', sample_video, fps=10)"
      ],
      "metadata": {
        "id": "eAXNUr1-Bl1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "489e0a47-98ce-4c4b-ad7f-7e037d9cb0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0.0, 13.533552169799805]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot an example frame of the video and the video's alignment\n",
        "tf.strings.reduce_join([num_to_char(word) for word in sample_alignments])\n",
        "plt.imshow(sample_video[70])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "3Miil5foWMer",
        "outputId": "be27f053-ae19-4e48-c17d-4da839bd1708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x782fdc1f53c0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Model"
      ],
      "metadata": {
        "id": "eEGwLCBgSRak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Model Architecture"
      ],
      "metadata": {
        "id": "lccJ99GESTbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = sample_video.shape\n",
        "input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xag7N1WkBdIC",
        "outputId": "5dda3ae9-2f87-4388-a549-0283b21a688f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75, 100, 120, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  # Three layers of 3D/spatiotemporal convolutions.\n",
        "  model.add(Conv3D(128, 3, input_shape=input_shape, padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "  model.add(Conv3D(256, 3, padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "  model.add(Conv3D(75, 3, padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "  # Flattens each time slice independently.\n",
        "  model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "  # Two layers of Bi-LSTM's.\n",
        "  # return_sequences=True makes the the network output a sequence of predictions, one for each time step of the input sequence.\n",
        "  model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "  model.add(Dropout(.5))\n",
        "\n",
        "  model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "  model.add(Dropout(.5))\n",
        "\n",
        "  # Linear transformation (dense layer) and output (softmax layer).\n",
        "  model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "BZtDo1xVCnX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_example = create_model()\n",
        "model_example.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg89hwKgCsdZ",
        "outputId": "ab6a5dd2-7e76-4d78-ea8d-8d9232c7edff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 75, 100, 120, 128  3584      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 75, 100, 120, 128  0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 75, 50, 60, 128)  0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 75, 50, 60, 256)   884992    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 75, 50, 60, 256)   0         \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 75, 25, 30, 256)  0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 75, 25, 30, 75)    518475    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 75, 25, 30, 75)    0         \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 75, 12, 15, 75)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 75, 13500)        0         \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 75, 256)          13956096  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 75, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 75, 256)          394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 75, 256)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 75, 41)            10537     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,767,924\n",
            "Trainable params: 15,767,924\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show example"
      ],
      "metadata": {
        "id": "VcpV-3keCwz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model_example.predict(np.expand_dims(sample_video, axis=0))[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGzHVroRC18i",
        "outputId": "a3381b1e-6d13-4cf1-b6cc-b47ccc774942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in yhat])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFixvFbNC-IO",
        "outputId": "3c2d54db-c31b-4765-f7af-d7225d8372f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'pppppppppppppppppppppppppppppppppppppppppppppppbbbbbbbbbbbbbbbbbbbbaaa'>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show Shapes"
      ],
      "metadata": {
        "id": "oJXJcUqiDI3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input shape should be (None, 75, 100, 120, 1) because of the pre-processing of the video and reshaping each fram to the size of (100,120)"
      ],
      "metadata": {
        "id": "Mcjapp5SDNo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_example.input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxT8PQMvDCyT",
        "outputId": "1494bf43-bcbc-4caa-b752-f02202568cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 75, 100, 120, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output shape should be (None, 75, 41) because of the number of frames in the video (75) and the number of characters in the vocabulary (41)"
      ],
      "metadata": {
        "id": "Dg61vzxhDcxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_example.output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqrRlTcyDFt8",
        "outputId": "860730b5-a0fa-48dc-cc96-1f5669b80d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 75, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Loss Function"
      ],
      "metadata": {
        "id": "xXObm3PFUdsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CTC (Connectionist Temporal Classification)** is a commonly used technique in automatic speech recognition and other sequence-to-sequence tasks where the alignment between the input sequence and the target sequence is not one-to-one.\n",
        "\n",
        "The `ctc_batch_cost` refers to the loss function and it calculates the CTC loss for a batch of input-output sequence pairs."
      ],
      "metadata": {
        "id": "VuezFsn8FpFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "0s7WHUP7FJXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose Parameters"
      ],
      "metadata": {
        "id": "0drr-B1rSbVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ],
      "metadata": {
        "id": "jD_mWJ1mGn4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001)"
      ],
      "metadata": {
        "id": "eDyRONI8GmqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scheduler"
      ],
      "metadata": {
        "id": "PR85E4bMEiAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose the ReduceLROnPlateau scheduler from this list for the base model because tensoflow has a built-in implementation for it unlike CosineAnnealingLR for example.\n",
        "But I think it is a good idea to play with these options when running the experiments"
      ],
      "metadata": {
        "id": "uqyeGLhOJKYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **StepLR:** This scheduler reduces the learning rate by a factor gamma at specified milestones or epochs. It is commonly used when you want to decrease the learning rate at specific intervals during training.\n",
        "\n",
        "2. **ReduceLROnPlateau:** This scheduler reduces the learning rate when a monitored metric (such as validation loss) has stopped improving. It is useful when you want to dynamically adjust the learning rate based on the model's performance.\n",
        "\n",
        "3. **CosineAnnealingLR:** This scheduler uses a cosine annealing schedule to gradually reduce the learning rate. It is effective in scenarios where you want to gradually decrease the learning rate over a specified number of epochs.\n",
        "\n",
        "4. **CyclicLR:** This scheduler cycles the learning rate between specified minimum and maximum values. It can help the model escape from poor local optima and explore different areas of the loss landscape.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_yyUcO6uI0bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onPlateau_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Which metric to monitor (e.g., validation loss)\n",
        "    factor=0.1,          # Factor by which the learning rate will be reduced (new_lr = lr * factor)\n",
        "    patience=3,          # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    verbose=1,           # Verbosity mode (0 = silent, 1 = update messages)\n",
        "    min_delta=1e-4,      # Minimum change in monitored metric to qualify as an improvement\n",
        "    cooldown=0,          # Number of epochs to wait after reducing learning rate before resuming normal operation\n",
        "    min_lr=0             # Lower bound on the learning rate\n",
        ")"
      ],
      "metadata": {
        "id": "fOvXJfC1EhJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step_decay(epoch, epochs_drop = 10):\n",
        "    initial_lr = 0.0001\n",
        "    drop = 0.5       # factor by which the learning rate will be reduced\n",
        "    lr = initial_lr * drop ** (epoch // epochs_drop)\n",
        "    return lr"
      ],
      "metadata": {
        "id": "7-2nIk93wzNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onEpoch_scheduler = LearningRateScheduler(lambda epoch: step_decay(epoch, epochs_drop=2))"
      ],
      "metadata": {
        "id": "h3hTTXhdu_31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Callbacks"
      ],
      "metadata": {
        "id": "eDb3PbIoKmIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=False)"
      ],
      "metadata": {
        "id": "KE0FCpxfKs9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the Model"
      ],
      "metadata": {
        "id": "lG1tp6r9Letx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_example.compile(optimizer=optimizer, loss=CTCLoss)"
      ],
      "metadata": {
        "id": "Zpi0sEOaLYJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments and Training"
      ],
      "metadata": {
        "id": "6RqZpVVnSrUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Experiment"
      ],
      "metadata": {
        "id": "Dz0iLM98StJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The base model without any schedulers"
      ],
      "metadata": {
        "id": "8pdc2jRbO8CN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose Parameters"
      ],
      "metadata": {
        "id": "FoFKkKBDK1nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 6"
      ],
      "metadata": {
        "id": "S44DZ8-DK6v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "VCeAmG1_ThR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_model = create_model()\n",
        "first_model.compile(optimizer=optimizer, loss=CTCLoss)"
      ],
      "metadata": {
        "id": "VKqcrMJZuIUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_model.fit(train, validation_data=test, epochs=epochs, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "phrzogEHKuoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d999e96-2a15-4fe9-984e-0f9d585f5ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Predictions and Metrics"
      ],
      "metadata": {
        "id": "jtCMrvDhTd1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a single prediction"
      ],
      "metadata": {
        "id": "xmyfY_B5dRvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test.as_numpy_iterator()\n",
        "first_sample = test_data.next()"
      ],
      "metadata": {
        "id": "YJdFwYzxdRbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('~'*100, 'REAL TEXT')\n",
        "first_y_true = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in first_sample[1]]"
      ],
      "metadata": {
        "id": "2J7IqdV-d8Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_yhat = first_model.predict(first_sample[0])\n",
        "first_yhat_decoded = tf.keras.backend.ctc_decode(first_yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
      ],
      "metadata": {
        "id": "9HHF__aSeOFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('~'*100, 'PREDICTIONS')\n",
        "first_y_pred = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in first_yhat_decoded]"
      ],
      "metadata": {
        "id": "JaiDukf0eO0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the tensors to string for the accuracy calculations"
      ],
      "metadata": {
        "id": "9Tc10s1YN6M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_y_true_string = tensors_to_strings(first_y_true)\n",
        "first_y_pred_string = tensors_to_strings(first_y_pred)"
      ],
      "metadata": {
        "id": "k-JnlnhDN6ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(first_y_true_string)\n",
        "print(first_y_pred_string)"
      ],
      "metadata": {
        "id": "cZR4nVMd5BCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy using nlp"
      ],
      "metadata": {
        "id": "F-_4g_sHN6ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp_accuracy(first_y_true_string, first_y_pred_string))"
      ],
      "metadata": {
        "id": "5OLVyjvkN6ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy using Levenstein"
      ],
      "metadata": {
        "id": "1jiFDB3ZN6ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(levenstein_accuracy(first_y_true_string, first_y_pred_string))"
      ],
      "metadata": {
        "id": "RemyNk0gN6ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy using wer and cer"
      ],
      "metadata": {
        "id": "VZ6phg_HN6ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer, cer = wer_and_cer_accuracy(first_y_true_string, first_y_pred_string)\n",
        "print(\"WER: \", wer)\n",
        "print(\"CER: \", cer)"
      ],
      "metadata": {
        "id": "NxG15-ObN6ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Experiment"
      ],
      "metadata": {
        "id": "9L9R_-ZrSxoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base model but with \"on-epoch\" scheduler to the same number of epochs"
      ],
      "metadata": {
        "id": "gfodtb7RPBAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose Parameters"
      ],
      "metadata": {
        "id": "CjIfdT-4S2py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 6"
      ],
      "metadata": {
        "id": "Cf9_kirGl3mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_callback = onEpoch_scheduler"
      ],
      "metadata": {
        "id": "12D2lFOCx6E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "2Huye3rsl3mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_model = create_model()\n",
        "second_model.compile(optimizer=optimizer, loss=CTCLoss)"
      ],
      "metadata": {
        "id": "mSYOOBn2uaSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_model.fit(train, validation_data=test, epochs=epochs, callbacks=[checkpoint_callback, schedule_callback])"
      ],
      "metadata": {
        "id": "Az12MjD_l3mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Predictions and Metrics"
      ],
      "metadata": {
        "id": "NnE1KN6NTc94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a single prediction"
      ],
      "metadata": {
        "id": "WDplyHPIelF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test.as_numpy_iterator()\n",
        "second_sample = test_data.next()"
      ],
      "metadata": {
        "id": "06wZPnfEelF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('~'*100, 'REAL TEXT')\n",
        "second_y_true = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in second_sample[1]]"
      ],
      "metadata": {
        "id": "SCIZkCf9elF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_yhat = second_model.predict(second_sample[0])\n",
        "second_yhat_decoded = tf.keras.backend.ctc_decode(second_yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
      ],
      "metadata": {
        "id": "dF1RSp2AelF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('~'*100, 'PREDICTIONS')\n",
        "second_y_pred = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in second_yhat_decoded]"
      ],
      "metadata": {
        "id": "RATLtGOxelF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the tensors to string for the accuracy calculations"
      ],
      "metadata": {
        "id": "7tBX34qdNZkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_y_true_string = tensors_to_strings(second_y_true)\n",
        "second_y_pred_string = tensors_to_strings(second_y_pred)"
      ],
      "metadata": {
        "id": "v9tnXiBMNZkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy using nlp"
      ],
      "metadata": {
        "id": "wPiLTKJTNZkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp_accuracy(second_y_true_string, second_y_pred_string))"
      ],
      "metadata": {
        "id": "3Wt2FWZzNZkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy using Levenstein"
      ],
      "metadata": {
        "id": "LfwkBuHTNZkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(levenstein_accuracy(second_y_true_string, second_y_pred_string))"
      ],
      "metadata": {
        "id": "C17SMJ3SNZkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy using wer and cer"
      ],
      "metadata": {
        "id": "2EwYB3UCNZkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer, cer = wer_and_cer_accuracy(second_y_true_string, second_y_pred_string)\n",
        "print(\"WER: \" + wer)\n",
        "print(\"CER: \" + cer)"
      ],
      "metadata": {
        "id": "O78vRtziNZkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Third Experiment"
      ],
      "metadata": {
        "id": "H8Fs_VbDSz83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base model but with \"on-plateau\" scheduler to the same number of epochs"
      ],
      "metadata": {
        "id": "EnpsHbgOPSDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose Parameters"
      ],
      "metadata": {
        "id": "htRWo1HZS5jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 6"
      ],
      "metadata": {
        "id": "Il1z70WiyOhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_callback = onPlateau_scheduler"
      ],
      "metadata": {
        "id": "SaL1L80syOhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "lHH2W0QtTPuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "third_model = create_model()\n",
        "third_model.compile(optimizer=optimizer, loss=CTCLoss)"
      ],
      "metadata": {
        "id": "Tlsuw7_puh4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_model.fit(train, validation_data=test, epochs=epochs, callbacks=[checkpoint_callback, schedule_callback])"
      ],
      "metadata": {
        "id": "0CqD_7YryR4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Predictions and Metrics"
      ],
      "metadata": {
        "id": "cVpFr6piTRtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a single prediction"
      ],
      "metadata": {
        "id": "jYD3Jay5e_Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test.as_numpy_iterator()\n",
        "third_sample = test_data.next()"
      ],
      "metadata": {
        "id": "Uis5WyY9e_Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('~'*100, 'REAL TEXT')\n",
        "third_y_true = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in third_sample[1]]"
      ],
      "metadata": {
        "id": "TSYSexkMe_Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_yhat = third_model.predict(third_sample[0])\n",
        "third_yhat_decoded = tf.keras.backend.ctc_decode(second_yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
      ],
      "metadata": {
        "id": "KySrFzyie_Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('~'*100, 'PREDICTIONS')\n",
        "third_y_pred = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in third_yhat_decoded]"
      ],
      "metadata": {
        "id": "kDLjrRxse_Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the tensors to string for the accuracy calculations"
      ],
      "metadata": {
        "id": "6mSA-QC8YIj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "third_y_true_string = tensors_to_strings(third_y_true)\n",
        "third_y_pred_string = tensors_to_strings(third_y_pred)"
      ],
      "metadata": {
        "id": "Lfb4GlKvWlMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy using nlp"
      ],
      "metadata": {
        "id": "BR7IWLjWVWmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp_accuracy(third_y_true_string, third_y_pred_string))"
      ],
      "metadata": {
        "id": "YvItuXLkYz5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy using Levenstein"
      ],
      "metadata": {
        "id": "gQi2rp-IVaYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(levenstein_accuracy(third_y_true_string, third_y_pred_string))"
      ],
      "metadata": {
        "id": "MOQN2NsPZB4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy using wer and cer"
      ],
      "metadata": {
        "id": "Q50btmNSVfNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wer, cer = wer_and_cer_accuracy(third_y_true_string, third_y_pred_string)\n",
        "print(\"WER: \" + wer)\n",
        "print(\"CER: \" + cer)"
      ],
      "metadata": {
        "id": "EGCyM8xfMn_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Best Model"
      ],
      "metadata": {
        "id": "4kymxaESTDCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# final_model ="
      ],
      "metadata": {
        "id": "ARPmW5NAupdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_model.save('model_40e.h5')"
      ],
      "metadata": {
        "id": "v9XOB1-uNMi0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}